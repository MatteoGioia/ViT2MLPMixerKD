{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoGioia/ViT2MLPMixerKD/blob/main/ViT2MLPKD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL7l7ZJI61rQ"
      },
      "source": [
        "# Knowledge distillation\n",
        "In this notebook, we will try to distill the knowledge of a Vision Transformer into a MLP Mixer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES_z2lrFzS4Q"
      },
      "source": [
        "##0. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EvwYoj0z8Ge"
      },
      "source": [
        "### 0.1 Downloads and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-12-13T14:10:23.954779Z",
          "iopub.status.busy": "2022-12-13T14:10:23.954411Z",
          "iopub.status.idle": "2022-12-13T14:10:39.872727Z",
          "shell.execute_reply": "2022-12-13T14:10:39.871578Z",
          "shell.execute_reply.started": "2022-12-13T14:10:23.954713Z"
        },
        "id": "4Ol5yDer7LaO",
        "outputId": "8fbc1655-b6c2-4d0b-c958-d030d7ba9029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.8 MB 27.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 66.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 800 kB 57.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 68.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 27.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 512 kB 68.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 79.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 72.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 38.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 68.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 74.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 77.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 63.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 79.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 71.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 99.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 73.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 86.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 69.5 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 41 kB 582 kB/s \n",
            "\u001b[K     |████████████████████████████████| 549 kB 32.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title Downloads\n",
        "!pip install -q transformers datasets[vision] pytorch-lightning\n",
        "!pip install -q wandb\n",
        "!pip install -q einops\n",
        "!pip install -q timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-12-13T14:10:39.875167Z",
          "iopub.status.busy": "2022-12-13T14:10:39.874826Z",
          "iopub.status.idle": "2022-12-13T14:10:42.240821Z",
          "shell.execute_reply": "2022-12-13T14:10:42.240056Z",
          "shell.execute_reply.started": "2022-12-13T14:10:39.875130Z"
        },
        "id": "WumRkwLd7SKG",
        "outputId": "636e0f80-bd3f-49cd-f09b-c2e1164bb649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_lite.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are going to train the distillation on cuda\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "\n",
        "# general imports\n",
        "from google.colab import drive\n",
        "from typing import *\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import wandb\n",
        "\n",
        "# pytorch imports\n",
        "import torchvision\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import callbacks\n",
        "import transformers\n",
        "#from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import einops\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#mlp mixer import\n",
        "import timm\n",
        "\n",
        "seed : int = 42\n",
        "device : str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "pl.seed_everything(seed)\n",
        "print(f\"You are going to train the distillation on {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Move to the project folder\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "%cd /content/drive/MyDrive\n",
        "\n",
        "if not os.path.exists(\"ViT2MLP\"):\n",
        "  os.mkdir(\"ViT2MLP\")\n",
        "\n",
        "%cd ViT2MLP"
      ],
      "metadata": {
        "id": "GrSlopjiUeLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-12-13T14:15:03.886461Z",
          "iopub.status.busy": "2022-12-13T14:15:03.886055Z",
          "iopub.status.idle": "2022-12-13T14:25:02.508847Z",
          "shell.execute_reply": "2022-12-13T14:25:02.507616Z",
          "shell.execute_reply.started": "2022-12-13T14:15:03.886436Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "m7LPJLqcTDwa",
        "outputId": "38e74689-625b-4695-a488-0d237e691ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-13 14:15:04--  https://pjreddie.com/media/files/imagenet64.tar\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10033909760 (9.3G) [application/octet-stream]\n",
            "Saving to: ‘imagenet64.tar’\n",
            "\n",
            "imagenet64.tar      100%[===================>]   9.34G  23.9MB/s    in 9m 57s  \n",
            "\n",
            "2022-12-13 14:25:01 (16.0 MB/s) - ‘imagenet64.tar’ saved [10033909760/10033909760]\n",
            "\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './imagenet64/train/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[38;5;66;03m#testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=4)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m trainset, testset\n\u001b[0;32m---> 27\u001b[0m imnet64_train, imnet64_test \u001b[38;5;241m=\u001b[39m \u001b[43mget_imagenet64_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mget_imagenet64_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m transform_train \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      9\u001b[0m   torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m64\u001b[39m), \u001b[38;5;66;03m# Takes images smaller than 64 and enlarges them\u001b[39;00m\n\u001b[1;32m     10\u001b[0m   torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mRandomCrop(\u001b[38;5;241m64\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, padding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;66;03m# Take 64x64 crops from 72x72 padded images\u001b[39;00m\n\u001b[1;32m     11\u001b[0m   torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(),    \u001b[38;5;66;03m# 50% of time flip image along y-axis\u001b[39;00m\n\u001b[1;32m     12\u001b[0m   torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     13\u001b[0m ])\n\u001b[1;32m     15\u001b[0m transform_test \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     16\u001b[0m   torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     17\u001b[0m ])\n\u001b[0;32m---> 19\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./imagenet64/train/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m testset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./imagenet64/val/\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform_test)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    304\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m ):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    137\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 145\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py:219\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './imagenet64/train/'"
          ]
        }
      ],
      "source": [
        "#@title Download imagenet64\n",
        "#Warning: the total size (zip + untarred file) is 20 gb!\n",
        "\n",
        "!wget https://pjreddie.com/media/files/imagenet64.tar \n",
        "!tar -xvf imagenet64.tar\n",
        "!rm -rf imagenet64.tar\n",
        "\n",
        "def get_imagenet64_data():\n",
        "  # Data augmentation transformations. Not for Testing!\n",
        "  transform_train = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(64), # Takes images smaller than 64 and enlarges them\n",
        "    torchvision.transforms.RandomCrop(64, padding=4, padding_mode='edge'), # Take 64x64 crops from 72x72 padded images\n",
        "    torchvision.transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n",
        "    torchvision.transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  transform_test = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  trainset = torchvision.datasets.ImageFolder(root='./imagenet64/train/', transform=transform_train)\n",
        "  #trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "  testset = torchvision.datasets.ImageFolder(root='./imagenet64/val/', transform=transform_test)\n",
        "  #testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=4)\n",
        "\n",
        "  return trainset, testset\n",
        "\n",
        "imnet64_train, imnet64_test = get_imagenet64_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a752f2fc3ae9421da030d4070b652d86"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-12-13T16:04:18.250777Z",
          "iopub.status.busy": "2022-12-13T16:04:18.250498Z"
        },
        "id": "_yAlyRDW8fwM",
        "outputId": "50dea1cd-0c24-4a70-8774-6b5df3740c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar-100-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a752f2fc3ae9421da030d4070b652d86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-100-python.tar.gz to .\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#@title Download cifar100\n",
        "cifar100_train = torchvision.datasets.CIFAR100(root = \".\",\n",
        "                                               train = True,\n",
        "                                               download = True,\n",
        "                                               transform=torchvision.transforms.functional.pil_to_tensor)\n",
        "cifar100_test = torchvision.datasets.CIFAR100(root = \".\",\n",
        "                                               train = False,\n",
        "                                               download = True,\n",
        "                                               transform=torchvision.transforms.functional.pil_to_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqXSkG6p0C5A"
      },
      "source": [
        "###0.2 Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2022-12-13T11:27:24.656197Z",
          "iopub.status.busy": "2022-12-13T11:27:24.655858Z",
          "iopub.status.idle": "2022-12-13T11:27:24.661024Z",
          "shell.execute_reply": "2022-12-13T11:27:24.660167Z",
          "shell.execute_reply.started": "2022-12-13T11:27:24.656173Z"
        },
        "id": "MLtary4p_Z_B"
      },
      "outputs": [],
      "source": [
        "#@title Visualization function\n",
        "def visualize(datapoint : int, dataset : torchvision.datasets):\n",
        "    image, label = dataset[datapoint]\n",
        "    plt.title(f\"Ground truth: {dataset.classes[label]}\")\n",
        "    plt.imshow(torchvision.transforms.functional.to_pil_image(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2022-12-13T11:21:35.481533Z",
          "iopub.status.busy": "2022-12-13T11:21:35.480512Z",
          "iopub.status.idle": "2022-12-13T11:21:35.486426Z",
          "shell.execute_reply": "2022-12-13T11:21:35.485924Z",
          "shell.execute_reply.started": "2022-12-13T11:21:35.481504Z"
        },
        "id": "qW2bXu6dAYls"
      },
      "outputs": [],
      "source": [
        "#@title Function to output a prediction of the teacher\n",
        "def predict(image : torch.Tensor,\n",
        "            model : nn.Module,\n",
        "            feature_extractor : Any = None) -> str:\n",
        "    with torch.no_grad():\n",
        "        if feature_extractor is None:\n",
        "            logits = model(image)\n",
        "        else:\n",
        "            inputs : torch.Tensor = feature_extractor(image, return_tensors=\"pt\").to(device)\n",
        "            logits = model(**inputs).logits\n",
        "      \n",
        "    # model predicts one of the classes\n",
        "    predicted_label : int = logits.argmax(-1).item()\n",
        "   \n",
        "    return predicted_label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2022-12-13T11:21:50.516187Z",
          "iopub.status.busy": "2022-12-13T11:21:50.515291Z",
          "iopub.status.idle": "2022-12-13T11:21:50.520086Z",
          "shell.execute_reply": "2022-12-13T11:21:50.519416Z",
          "shell.execute_reply.started": "2022-12-13T11:21:50.516156Z"
        },
        "id": "MKxP7OVI5pTb"
      },
      "outputs": [],
      "source": [
        "#@title Count the parameters of a model\n",
        "def count_params(model : nn.Module) -> int:\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    param_num = sum([np.prod(p.size()) for p in parameters]) / 1_000_000\n",
        "    return param_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjYPKIo8zW_7"
      },
      "source": [
        "##1. Code for the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtgQ0OHG21PO"
      },
      "source": [
        "###1.1 Pre-trained teacher (ViT)\n",
        "Load ViT finetuned on Imagenet1k or CIFAR100. To load the non fine-tuned version use **\"google/vit-base-patch16-224-im21k\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcazhnqFv0Lx"
      },
      "source": [
        "References:\n",
        "- [main transformer docs](https:huggingface.co/docs/transformers/index) \n",
        "- [ViT Docs](https://huggingface.co/docs/transformers/model_doc/vit)\n",
        "- [lighting finetuning example](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/VisionTransformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-12-13T11:25:03.117029Z",
          "iopub.status.busy": "2022-12-13T11:25:03.116686Z",
          "iopub.status.idle": "2022-12-13T11:25:04.457114Z",
          "shell.execute_reply": "2022-12-13T11:25:04.456038Z",
          "shell.execute_reply.started": "2022-12-13T11:25:03.117004Z"
        },
        "id": "WsSKp30aAMah",
        "outputId": "c9556d6a-8c37-402a-b851-2d2790b598c3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b133d38fdc244adaae2aa780467acbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/265 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e03333546194f0fa9a38d9c3ea12bf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/68.0k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b759dd3c3b784fbc87398976d641c97a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/755M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable Parameters: 197.767M\n"
          ]
        }
      ],
      "source": [
        "#@title Load the model\n",
        "cifar100_vit = \"Ahmed9275/Vit-Cifar100\"\n",
        "imagenet1k_vit = \"google/vit-base-patch16-224\"\n",
        "tuned_on : str = \"imagenet1k\" #@param['cifar100', 'imagenet1k']\n",
        "if tuned_on == \"cifar100\":\n",
        "    model_str = cifar100_vit\n",
        "else:\n",
        "    model_str = imagenet1k_vit\n",
        "\n",
        "\n",
        "feature_extractor = transformers.ViTFeatureExtractor.from_pretrained(model_str)if \n",
        "\n",
        "teacher = transformers.ViTForImageClassification.from_pretrained(model_str).to(device)\n",
        "print('Trainable Parameters: %.3fM' % count_params(teacher))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "execution": {
          "iopub.execute_input": "2022-12-13T11:27:26.473005Z",
          "iopub.status.busy": "2022-12-13T11:27:26.472664Z",
          "iopub.status.idle": "2022-12-13T11:27:26.593420Z",
          "shell.execute_reply": "2022-12-13T11:27:26.592613Z",
          "shell.execute_reply.started": "2022-12-13T11:27:26.472980Z"
        },
        "id": "RBCle0TPyy2b",
        "outputId": "1181bc7e-5b3c-45f8-8ccd-38b9099bfa78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Predicted: tench, Tinca tinca\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Qualitative comparison with ground truth {run : \"auto\"}\n",
        "datapoint_number : int = 1 #@param{type:\"integer\"}\n",
        "\n",
        "dataset = cifar100_test if tuned_on == \"cifar100\" else imnet64_test\n",
        "try:\n",
        "    visualize(datapoint_number, dataset)\n",
        "    label : int = predict(dataset[datapoint_number][0], teacher, feature_extractor)\n",
        "    prediction : str = teacher.config.id2label[label]\n",
        "    print(f\"Predicted: {prediction}\")\n",
        "except IndexError:\n",
        "    print(f\"The dataset max index is {len(dataset)-1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "execution": {
          "iopub.execute_input": "2022-12-12T22:04:48.515398Z",
          "iopub.status.busy": "2022-12-12T22:04:48.514547Z",
          "iopub.status.idle": "2022-12-12T22:04:48.522270Z",
          "shell.execute_reply": "2022-12-12T22:04:48.521331Z",
          "shell.execute_reply.started": "2022-12-12T22:04:48.515370Z"
        },
        "id": "jCqhJyWDHUgL",
        "outputId": "e2478eab-a09c-4731-e782-db2b7d6f5b68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ncorrect = 0\\nfor i in tqdm(range(len(dataset))):\\n    pr_label = predict(dataset[i][0], teacher, feature_extractor)\\n    gt_label = dataset[i][1]\\n    if pr_label == gt_label:\\n        correct += 1\\naccuracy = round(correct*100 / len(dataset),2)\\nprint(f\"The accuracy of the model for the dataset {tuned_on} is: {accuracy}%\")\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Quantitative result: Accuracy\n",
        "'''\n",
        "Warning: this cell takes 15min to be executed (on GPU).\n",
        "'''\n",
        "'''\n",
        "correct = 0\n",
        "for i in tqdm(range(len(dataset))):\n",
        "    pr_label = predict(dataset[i][0], teacher, feature_extractor)\n",
        "    gt_label = dataset[i][1]\n",
        "    if pr_label == gt_label:\n",
        "        correct += 1\n",
        "accuracy = round(correct*100 / len(dataset),2)\n",
        "print(f\"The accuracy of the model for the dataset {tuned_on} is: {accuracy}%\")\n",
        "'''\n",
        "##### TODO remove (?) ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m4IdUu7-7QI"
      },
      "source": [
        "###1.2 Student (MLP mixer)\n",
        "The code for the MLP mixer was taken from this repository: [image_models](https://github.com/rwightman/pytorch-image-models).\n",
        "\n",
        "Credit: [Ross Wightman](https://github.com/rwightman) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2022-12-13T11:27:40.321681Z",
          "iopub.status.busy": "2022-12-13T11:27:40.321335Z",
          "iopub.status.idle": "2022-12-13T11:27:40.338091Z",
          "shell.execute_reply": "2022-12-13T11:27:40.337307Z",
          "shell.execute_reply.started": "2022-12-13T11:27:40.321656Z"
        },
        "id": "PM3JwgZGERRH"
      },
      "outputs": [],
      "source": [
        "#@title [Timm](https://huggingface.co/docs/timm/index) implementation\n",
        "class LitMixer(pl.LightningModule):\n",
        "    def __init__(self,\n",
        "                 num_classes : int,\n",
        "                 img_size : int,\n",
        "                 patch_size : int,\n",
        "                 num_blocks : int,\n",
        "                 embed_dim : int,\n",
        "                 in_chans : int = 3,\n",
        "                 drop_rate : float = 0.0,\n",
        "                 drop_path_rate : float = 0.0,\n",
        "                 learning_rate : float = 0.001,\n",
        "                 act_layer : Callable = nn.GELU,\n",
        "                 distillating : str = None,\n",
        "                 distillation_prob : float = None):\n",
        "        super().__init__()\n",
        "        assert(distillation_prob is None or distillating != \"random\")\n",
        "\n",
        "        self.mixer = timm.models.mlp_mixer.MlpMixer(num_classes = num_classes,\n",
        "                     img_size = img_size,\n",
        "                     in_chans = in_chans,\n",
        "                     patch_size = patch_size,\n",
        "                     num_blocks = num_blocks,\n",
        "                     act_layer = act_layer,\n",
        "                     drop_rate = drop_rate,\n",
        "                     drop_path_rate = drop_path_rate,\n",
        "                     embed_dim = embed_dim)\n",
        "\n",
        "        self.lr = learning_rate\n",
        "        self.distillating = distillating\n",
        "        self.distillation_prob = distillation_prob\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        ## logging attributes\n",
        "        self.loss = { \"train\" : 0, \"val\" : 0, \"test\" : 0 }\n",
        "        self.accuracy = { \"train\" : 0, \"val\" : 0, \"test\" : 0 }\n",
        "        self.tot = { \"train\" : 0, \"val\" : 0, \"test\" : 0 }\n",
        "        self.first_test = True\n",
        "\n",
        "        super().save_hyperparameters()\n",
        "    \n",
        "    def step(self, batch : torch.Tensor ,step_type : str) -> torch.Tensor:\n",
        "        # get ground truth and data\n",
        "        if step_type == \"test\":\n",
        "            data, labels = batch\n",
        "            gt : torch.Tensor = labels\n",
        "        else:\n",
        "            data, labels, teacher_labels = batch\n",
        "            if self.distillating is None:\n",
        "                gt : torch.Tensor = labels\n",
        "            else:\n",
        "                teacher_labels = torch.nn.functional.softmax(teacher_labels, dim = -1)\n",
        "                if self.distillating == \"soft\":\n",
        "                    gt : torch.Tensor = teacher_labels\n",
        "                elif self.distillating == \"hard\":\n",
        "                    gt : torch.Tensor = teacher_labels.argmax(dim = -1)\n",
        "                elif self.distillating == \"random\":\n",
        "                    r : float = random.random()\n",
        "                    if r <= self.distillation_prob:\n",
        "                        gt : torch.Tensor = teacher_labels\n",
        "                    else:\n",
        "                        gt : torch.Tensor = labels\n",
        "                elif self.distillating == \"weighted\":\n",
        "                    gt = labels\n",
        "                    gt_t : torch.Tensor = teacher_labels\n",
        "        \n",
        "        batch_size : int = labels.shape[0]\n",
        "\n",
        "        # compute predictions\n",
        "        logits = self.mixer(data.float())\n",
        "        if self.distillating == \"weighted\" and step_type != \"test\":\n",
        "          loss = 0.3 * self.loss_fn(logits,gt) + 0.7 * self.loss_fn(logits,gt_t)\n",
        "        else:\n",
        "          loss = self.loss_fn(logits,gt)\n",
        "        predictions = logits.argmax(dim = -1)\n",
        "\n",
        "        # update logging variables\n",
        "        self.loss[step_type] += loss.item()\n",
        "        self.accuracy[step_type]  += (predictions == labels).sum().item()\n",
        "        self.tot[step_type]  += batch_size\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch : torch.Tensor ,batch_idx : int):\n",
        "        return self.step(batch,\"train\")\n",
        "    \n",
        "    def validation_step(self,batch,batch_idx):\n",
        "        return self.step(batch,\"val\")\n",
        "    \n",
        "    def test_step(self,batch,batch_idx):\n",
        "        return self.step(batch,\"test\")\n",
        "    \n",
        "    def epoch_end(self, step_type : str, num_outputs : int) -> None:\n",
        "        # compute loss\n",
        "        avg_loss = self.loss[step_type] / num_outputs\n",
        "        self.loss[step_type] = 0\n",
        "        # compute accuracy\n",
        "        accuracy = self.accuracy[step_type] / self.tot[step_type]\n",
        "        self.accuracy[step_type] = 0\n",
        "        self.tot[step_type] = 0\n",
        "        # log\n",
        "        self.log(\"epoch\", float(self.current_epoch))\n",
        "        if step_type != \"test\":\n",
        "            self.log(f\"{step_type}_loss\",avg_loss)\n",
        "            self.log(f\"{step_type}_accuracy\",accuracy)\n",
        "        elif self.first_test:\n",
        "          self.log(\"test_loss_before\",avg_loss)\n",
        "          self.log(\"test_accuracy_before\",accuracy)\n",
        "          self.first_test = False\n",
        "        else:\n",
        "          self.log(\"test_loss_after\",avg_loss)\n",
        "          self.log(\"test_accuracy_after\",accuracy)\n",
        "    \n",
        "    def training_epoch_end(self, outputs) -> None:\n",
        "        self.epoch_end(\"train\",len(outputs))\n",
        "    \n",
        "    def validation_epoch_end(self, outputs) -> None:\n",
        "        self.epoch_end(\"val\",len(outputs))\n",
        "    \n",
        "    def test_epoch_end(self, outputs) -> None:\n",
        "        self.epoch_end(\"test\",len(outputs))\n",
        "\n",
        "    def configure_optimizers(self) -> torch.optim:\n",
        "        return torch.optim.AdamW(self.mixer.parameters(), lr = self.lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-12-13T11:27:48.042596Z",
          "iopub.status.busy": "2022-12-13T11:27:48.041979Z",
          "iopub.status.idle": "2022-12-13T11:27:48.086235Z",
          "shell.execute_reply": "2022-12-13T11:27:48.085460Z",
          "shell.execute_reply.started": "2022-12-13T11:27:48.042567Z"
        },
        "id": "4BA56dIAGl8L",
        "outputId": "21e5bb33-d8db-46d3-bb11-03afa24023ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable Parameters: 0.863M\n"
          ]
        }
      ],
      "source": [
        "#@title Student instantiation\n",
        "trained_on : str = \"imagenet\" #@param[\"cifar100\",\"imagenet\"]\n",
        "patch_size : int = 4 #@param{type: \"integer\"}\n",
        "num_blocks : int = 6 #@param{type: \"integer\"}\n",
        "embed_dim  : int = 128 #@param{type: \"integer\"}\n",
        "drop_rate : float = 0.24 #@param{type:\"number\"}\n",
        "drop_path_rate : float = 0.25 #@param{type:\"number\"}\n",
        "learning_rate : float = 0.0025 #@param{type:\"number\"}\n",
        "distillating : str = \"weighted\" #@param[\"soft\",\"hard\",\"random\",\"weighted\",\"no\"]\n",
        "distillation_prob : float = 0. #@param{type:\"number\"}\n",
        "if trained_on == \"cifar100\":\n",
        "    num_classes = 100\n",
        "    img_size = 32\n",
        "else:\n",
        "    num_classes = 1000\n",
        "    img_size = 64 \n",
        "student = LitMixer(num_classes = num_classes, \n",
        "                   img_size = img_size,\n",
        "                   patch_size = patch_size,\n",
        "                   num_blocks = num_blocks,\n",
        "                   embed_dim = embed_dim,\n",
        "                   drop_rate = drop_rate,\n",
        "                   drop_path_rate = drop_path_rate,\n",
        "                   learning_rate = learning_rate,\n",
        "                   distillating = distillating if distillating != \"no\" else None,\n",
        "                   distillation_prob = distillation_prob if distillating == \"random\" else None,\n",
        "                   )\n",
        "print('Trainable Parameters: %.3fM' % count_params(student))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzwRW42KdMsj"
      },
      "source": [
        "##2. Distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td1p_uw8x7Pi"
      },
      "source": [
        "###2.1 Computing labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QryLx7P6dckq"
      },
      "source": [
        "First of all we want to compute once and for all the teacher scores of the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-13T11:27:50.646992Z",
          "iopub.status.busy": "2022-12-13T11:27:50.646272Z",
          "iopub.status.idle": "2022-12-13T11:27:50.652500Z",
          "shell.execute_reply": "2022-12-13T11:27:50.651512Z",
          "shell.execute_reply.started": "2022-12-13T11:27:50.646964Z"
        },
        "id": "oS1uIiojdb3D"
      },
      "outputs": [],
      "source": [
        "def compute_scores(dataset : torch.utils.data.Dataset,\n",
        "                   teacher : torch.nn.Module, \n",
        "                   teacher_extractor : Any, # a feature extractor\n",
        "                   num_classes : int) -> torch.Tensor:\n",
        "    teacher_label = torch.zeros(len(dataset), num_classes)\n",
        "    for i,(image,_) in tqdm(enumerate(dataset)):\n",
        "        features = teacher_extractor(image,return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            label = teacher(**features).logits\n",
        "        teacher_label[i,:] = label\n",
        "    return teacher_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOcxWqXqzGXK"
      },
      "source": [
        "###2.2 Creating custom datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2022-12-13T11:31:01.756045Z",
          "iopub.status.busy": "2022-12-13T11:31:01.755381Z",
          "iopub.status.idle": "2022-12-13T11:31:01.768748Z",
          "shell.execute_reply": "2022-12-13T11:31:01.768123Z",
          "shell.execute_reply.started": "2022-12-13T11:31:01.756017Z"
        },
        "id": "dpwMnJ1j6ODN"
      },
      "outputs": [],
      "source": [
        "#@title Distillation dataset\n",
        "class DistillDataset(torch.utils.data.Dataset):\n",
        "    '''\n",
        "    A dataset for the distillation training.\n",
        "    This dataset wraps the original dataset toghether with the teacher ground truth.\n",
        "    '''\n",
        "    def __init__(self, \n",
        "                 original_dataset : torch.utils.data.Dataset,\n",
        "                 teacher_label_path : Path = None,\n",
        "                 teacher_model : torch.nn.Module = None,\n",
        "                 teacher_extractor : Any = None,\n",
        "                 save : bool = True, \n",
        "                 dataset_name : str = \"cifar100\"\n",
        "                 ):\n",
        "        assert(teacher_label_path is not None or teacher_model is not None)\n",
        "        super().__init__()\n",
        "        file_name = 'cifar100.pt' if dataset_name == \"cifar100\" else \"imnet64.pt\"\n",
        "        self.dataset = original_dataset\n",
        "        \n",
        "        num_classes = len(self.dataset.classes) if dataset_name == \"cifar100\" else 1000\n",
        "        \n",
        "        if not os.path.exists(teacher_label_path):\n",
        "          os.makedirs(teacher_label_path)\n",
        "          self.teacher_label = compute_scores(self.dataset, \n",
        "                                                teacher_model,\n",
        "                                                teacher_extractor,\n",
        "                                                num_classes\n",
        "                                                )\n",
        "          \n",
        "          if save:\n",
        "                with open(os.path.join(teacher_label_path , file_name), \"wb\") as tl:\n",
        "                    torch.save(self.teacher_label,tl)\n",
        "        \n",
        "        else:\n",
        "         \n",
        "            with open(os.path.join(teacher_label_path , file_name), \"rb\") as dl:\n",
        "                  self.teacher_label = torch.load(dl)\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.dataset[index][0], self.dataset[index][1] , self.teacher_label[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2022-12-13T11:31:57.981514Z",
          "iopub.status.busy": "2022-12-13T11:31:57.981164Z",
          "iopub.status.idle": "2022-12-13T12:02:25.066417Z",
          "shell.execute_reply": "2022-12-13T12:02:25.064842Z",
          "shell.execute_reply.started": "2022-12-13T11:31:57.981487Z"
        },
        "id": "E3gGWUDJxw9H",
        "outputId": "173653ce-7ed5-47fa-b347-39d83c53b173"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "70964it [30:26, 38.86it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title Train/Validation split\u001b[39;00m\n\u001b[1;32m      2\u001b[0m val_perc : \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.15\u001b[39m \u001b[38;5;66;03m#@param{type:\"number\"}\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDistillDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimnet64_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteacher_labels_imnet/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mteacher_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimnet64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m train_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mval_perc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[1;32m     10\u001b[0m val_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m-\u001b[39m train_len\n",
            "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mDistillDataset.__init__\u001b[0;34m(self, original_dataset, teacher_label_path, teacher_model, teacher_extractor, save, dataset_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(teacher_label_path):\n\u001b[1;32m     23\u001b[0m   os\u001b[38;5;241m.\u001b[39mmakedirs(teacher_label_path)\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteacher_label \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mteacher_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnum_classes\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(teacher_label_path , file_name), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tl:\n",
            "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mcompute_scores\u001b[0;34m(dataset, teacher, teacher_extractor, num_classes)\u001b[0m\n\u001b[1;32m      5\u001b[0m teacher_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(dataset), num_classes)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,(image,_) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataset)):\n\u001b[0;32m----> 7\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mteacher_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m         label \u001b[38;5;241m=\u001b[39m teacher(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfeatures)\u001b[38;5;241m.\u001b[39mlogits\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/vit/feature_extraction_vit.py:143\u001b[0m, in \u001b[0;36mViTFeatureExtractor.__call__\u001b[0;34m(self, images, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize(image\u001b[38;5;241m=\u001b[39mimage, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_normalize:\n\u001b[0;32m--> 143\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(image\u001b[38;5;241m=\u001b[39mimage, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_mean, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_std) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# return as BatchFeature\u001b[39;00m\n\u001b[1;32m    146\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/vit/feature_extraction_vit.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize(image\u001b[38;5;241m=\u001b[39mimage, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_normalize:\n\u001b[0;32m--> 143\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_std\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# return as BatchFeature\u001b[39;00m\n\u001b[1;32m    146\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/image_utils.py:202\u001b[0m, in \u001b[0;36mImageFeatureExtractionMixin.normalize\u001b[0;34m(self, image, mean, std)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_format_supported(image)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m--> 202\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mean, np\u001b[38;5;241m.\u001b[39mndarray):\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/image_utils.py:161\u001b[0m, in \u001b[0;36mImageFeatureExtractionMixin.to_numpy_array\u001b[0;34m(self, image, rescale, channel_first)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rescale:\n\u001b[1;32m    159\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channel_first \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    162\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Train/Validation split\n",
        "val_perc : float = 0.15 #@param{type:\"number\"}\n",
        "dataset = DistillDataset(imnet64_train, \n",
        "                         \"teacher_labels_imnet/\",\n",
        "                          teacher_model=teacher,\n",
        "                          teacher_extractor = feature_extractor,\n",
        "                          dataset_name = \"imnet64\"\n",
        "                         )\n",
        "train_len = int((1-val_perc) * len(dataset))\n",
        "val_len = len(dataset) - train_len\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset,\n",
        "                                                           lengths = [train_len, val_len],\n",
        "                                                           generator=torch.Generator(\"cpu\").manual_seed(seed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.status.busy": "2022-12-13T12:02:25.067045Z",
          "iopub.status.idle": "2022-12-13T12:02:25.067325Z",
          "shell.execute_reply": "2022-12-13T12:02:25.067202Z",
          "shell.execute_reply.started": "2022-12-13T12:02:25.067188Z"
        },
        "id": "GjfDKYyqDGo-"
      },
      "outputs": [],
      "source": [
        "#@title Pytorch Lightning datamodule definition\n",
        "class DistillDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, train_dataset, val_dataset, test_dataset, batch_size):\n",
        "        super().__init__()\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def train_dataloader(self) -> torch.utils.data.DataLoader:\n",
        "       return torch.utils.data.DataLoader(self.train_dataset, batch_size = self.batch_size, shuffle = True)\n",
        "\n",
        "    def val_dataloader(self) -> torch.utils.data.DataLoader:\n",
        "       return torch.utils.data.DataLoader(self.val_dataset, batch_size = self.batch_size, shuffle = False)\n",
        "    \n",
        "    def test_dataloader(self) -> torch.utils.data.DataLoader:\n",
        "       return torch.utils.data.DataLoader(self.test_dataset, batch_size = self.batch_size, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.status.busy": "2022-12-13T12:02:25.068686Z",
          "iopub.status.idle": "2022-12-13T12:02:25.068947Z",
          "shell.execute_reply": "2022-12-13T12:02:25.068838Z",
          "shell.execute_reply.started": "2022-12-13T12:02:25.068825Z"
        },
        "id": "yZfAFspcEEn4"
      },
      "outputs": [],
      "source": [
        "#@title Create a datamodule\n",
        "batch_size : int = 128 #@param{type:\"integer\"}\n",
        "datamodule = DistillDataModule(train_dataset,val_dataset,imnet64_test,batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89YUomqmx-pH"
      },
      "source": [
        "###2.3 Training the student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-13T12:02:25.069929Z",
          "iopub.status.idle": "2022-12-13T12:02:25.070186Z",
          "shell.execute_reply": "2022-12-13T12:02:25.070076Z",
          "shell.execute_reply.started": "2022-12-13T12:02:25.070064Z"
        },
        "id": "lp2LekQdQbDY"
      },
      "outputs": [],
      "source": [
        "#@title Weights & Biases initialization\n",
        "\n",
        "run_name : str = \"imnet_small_student\" #@param{type:\"string\"}\n",
        "\n",
        "#login\n",
        "wandb.login\n",
        "wandb.init(project=\"mixer-kd\", entity='mixer-kd')\n",
        "wandb.run.name = run_name\n",
        "\n",
        "#definition of the metrics to compute\n",
        "wandb.define_metric('epoch')\n",
        "wandb.define_metric('train_loss',step_metric='epoch')\n",
        "wandb.define_metric('test_loss_before',step_metric='epoch')\n",
        "wandb.define_metric('test_loss_after',step_metric='epoch')\n",
        "wandb.define_metric('val_loss',step_metric='epoch')\n",
        "wandb.define_metric('train_accuracy',step_metric='epoch')\n",
        "wandb.define_metric('val_accuracy',step_metric='epoch')\n",
        "wandb.define_metric('test_accuracy_before',step_metric='epoch')\n",
        "wandb.define_metric('test_accuracy_after',step_metric='epoch')\n",
        "\n",
        "#config of the run\n",
        "wandb.config.batch_size = batch_size\n",
        "wandb.config.val_perc = val_perc\n",
        "\n",
        "#definition of the pytorch lightning logger\n",
        "logger = pl.loggers.WandbLogger(name='run_1', project='mixer-kd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-13T12:02:25.071449Z",
          "iopub.status.idle": "2022-12-13T12:02:25.071757Z",
          "shell.execute_reply": "2022-12-13T12:02:25.071596Z",
          "shell.execute_reply.started": "2022-12-13T12:02:25.071584Z"
        },
        "id": "rHXGSY2o_q8E"
      },
      "outputs": [],
      "source": [
        "#@title Train the student\n",
        "epochs : int = 60 #@param{type:\"integer\"}\n",
        "\n",
        "# checkpoint to save the model with the best validation loss\n",
        "checkpoint = callbacks.ModelCheckpoint(\"checkpoints/\",\n",
        "                                       monitor=\"val_loss\",\n",
        "                                       mode=\"min\")\n",
        "\n",
        "# definition of the triner\n",
        "trainer = pl.Trainer(max_epochs=epochs,\n",
        "                     accelerator=device,\n",
        "                     logger=logger,\n",
        "                     callbacks=[checkpoint]\n",
        "                     )\n",
        "\n",
        "# training\n",
        "logger.watch(student)\n",
        "trainer.test(datamodule=datamodule,model = student) #test before training\n",
        "trainer.fit(datamodule=datamodule,model = student) #trainng\n",
        "student = LitMixer.load_from_checkpoint(checkpoint.best_model_path)\n",
        "student.first_test = False\n",
        "trainer.test(datamodule=datamodule,model = student) #test after training\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2022-12-12T22:42:24.391813Z",
          "iopub.status.busy": "2022-12-12T22:42:24.390895Z",
          "iopub.status.idle": "2022-12-12T22:42:24.572812Z",
          "shell.execute_reply": "2022-12-12T22:42:24.571778Z",
          "shell.execute_reply.started": "2022-12-12T22:42:24.391785Z"
        },
        "id": "by6pgVMpm8vi"
      },
      "outputs": [],
      "source": [
        "#@title Load a model from checkpoint\n",
        "checkpoint_path : str = \"last_checkpoint\" #@param{type:\"string\"}\n",
        "if checkpoint_path == \"last_checkpoint\":\n",
        "    checkpoint_path = checkpoint.best_model_path\n",
        "loaded_student = LitMixer.load_from_checkpoint(checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "execution": {
          "iopub.execute_input": "2022-12-12T22:42:33.343936Z",
          "iopub.status.busy": "2022-12-12T22:42:33.342990Z",
          "iopub.status.idle": "2022-12-12T22:42:33.507679Z",
          "shell.execute_reply": "2022-12-12T22:42:33.506827Z",
          "shell.execute_reply.started": "2022-12-12T22:42:33.343895Z"
        },
        "id": "buxcGxzpGJya",
        "outputId": "461b708a-00d8-4a66-c881-a5814988ec08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('woman', 'lamp')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Test qualitative results {run : 'auto'}\n",
        "datapoint_number = 600 #@param{type : \"integer\"}\n",
        "image, gt = cifar100_test[datapoint_number]\n",
        "image_pixels = torchvision.transforms.functional.to_pil_image(image)\n",
        "plt.imshow(image_pixels)\n",
        "pr = loaded_student.mixer(image.unsqueeze(0).float())\n",
        "#print(pr)\n",
        "dataset.dataset.classes[gt],  dataset.dataset.classes[pr.argmax().item()]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ES_z2lrFzS4Q",
        "TqXSkG6p0C5A",
        "AjYPKIo8zW_7",
        "GtgQ0OHG21PO",
        "0m4IdUu7-7QI",
        "xzwRW42KdMsj",
        "Td1p_uw8x7Pi"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}